Project Description: 
We have created a live camera feed app that utilizes a real-time text recognition SDK to perform a “Ctrl-F” in real life. The goal was to create a tool that could perform searches with a faster runtime than our own eyes. Once the user types into the textfield which keyword they are looking for, the app finds that word in the text the camera is pointed at and highlights that word over it in real-time. The rest of that sentence that includes the keyword is boxed to provide context for the user. This app supports 12 different languages. 

For the future, we would like to improve the algorithm so we can read smaller text and remove the slight delay as well as implement it on iOS. In addition, one of our use cases was to use this for messy handwritten notes. We created several samples using and Azure and Google API which are able to read messy handwriting, however it was much slower so we proceeded with ABBYY which is offline. 


The hardware devices, frameworks or tools you have used in the project:
-Android Studio 
-ABBYY Mobile OCR - real-time recognition SDK


Link to Presentation:

Google drive link: goo.gl/xJdNYr

or

PDF link: https://goo.gl/NNRKdr 



Instructions to run: 
-Tap on the app icon through your homepage

-Select the desired language from the dropdown menu on the top right

-Type the word you would like to search for into the “Enter your keywords” textbox

-Aim the camera towards the text you would like to search

-Tap “Start”

-Move your camera closer or farther away from the text based on the confidence level bar and the warning in the top left 
The keywords you searched will be highlighted and the entire line will have a outline for context 

-You just performed a Ctrl-F in real life!
